import os
import json
import random
import torch
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torchvision.transforms as transforms
from collections import defaultdict

def calculate_class_weights(dataset):
    print("âš–ï¸ SÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ± hesaplanÄ±yor...")

    # TÃ¼m etiketleri al ve 1 Ã§Ä±kararak 0-5 arasÄ±na Ã§ek
    labels = torch.tensor([int(p['label']) - 1 for p in dataset.pairs])

    # GÃ¼venlik iÃ§in 0-5 arasÄ±na sabitle
    labels = torch.clamp(labels, 0, 5)

    # bincount artÄ±k tam olarak 6 elemanlÄ± bir liste verecek
    class_counts = torch.bincount(labels, minlength=6)

    total = len(labels)
    weights = total / (6 * class_counts.float().clamp(min=1))
    print(weights)
    return weights / weights.min()


class PISCDataset(Dataset):
    def __init__(self, data_root, split='train', transform=None):
        self.data_root = data_root
        # KlasÃ¶r ismin 'image' olduÄŸu iÃ§in burayÄ± s'siz bÄ±raktÄ±k
        self.image_dir = os.path.join(data_root, 'image')

        split_file = os.path.join(data_root, 'relationship_split', f'relation_{split}idx.json')
        rel_file = os.path.join(data_root, 'relationship.json')
        info_file = os.path.join(data_root, 'annotation_image_info.json')

        with open(split_file, 'r') as f:
            active_ids = json.load(f)
        with open(rel_file, 'r') as f:
            rel_data = json.load(f)
        with open(info_file, 'r') as f:
            info_list = json.load(f)

        info_dict = {str(item['id']): item for item in info_list}
        self.label_names = ["Friends", "Family", "Couple", "Professional", "Commercial", "No Relation"]

        # TÃ¼m veriyi Ã¶nce topla
        all_pairs = []
        for img_id in active_ids:
            img_id_str = str(img_id)
            if img_id_str in rel_data and img_id_str in info_dict:
                img_pairs = rel_data[img_id_str]
                for pair_key, label_idx in img_pairs.items():
                    all_pairs.append({
                        'filename': f"{img_id_str}.jpg",
                        'label': int(label_idx)
                    })

        self.pairs = all_pairs

        random.seed(42)
        random.shuffle(self.pairs)

        self.transform = transform
        print(f"âœ… {split.upper()} YÃ¼klendi: {len(self.pairs)} Ã§ift bulundu.")

    def __len__(self):
        return len(self.pairs)

    def __getitem__(self, idx):
        pair_data = self.pairs[idx]
        img_path = os.path.join(self.image_dir, pair_data['filename'])

        # 1. GÃ¶rÃ¼ntÃ¼ YÃ¼kleme (Makale: ResNet-50 giriÅŸi iÃ§in derin Ã¶zellik Ã§Ä±karma [cite: 152])
        try:
            if os.path.exists(img_path):
                image = Image.open(img_path).convert('RGB')
            else:
                image = Image.new('RGB', (224, 224), color='gray')
        except Exception:
            image = Image.new('RGB', (224, 224), color='gray')

        # Veri ArtÄ±rÄ±mÄ± (Transformations)
        if self.transform:
            image = self.transform(image)

        # 2. Etiket ve Ä°liÅŸki Bilgisi
        raw_label = int(pair_data['label'])
        clean_label = max(0, min(raw_label - 1, 5))
        rel_name = self.label_names[clean_label]

        # 3. MAKALE UYUMLU: STRUCTURED TEXT EXTRACTION (BÃ¶lÃ¼m III-B)
        # Makale, LLM'in metinden "Aksiyon, Duygu, Sahne ve Ä°liÅŸki" Ã§Ä±kardÄ±ÄŸÄ±nÄ± belirtir[cite: 16, 133].
        # Bu bilgiler "Subject-State-Environment" hiyerarÅŸisinde dÃ¼zenlenmelidir[cite: 307].

        # Not: GerÃ§ek veride bu bilgiler yoksa, makaledeki triplet mantÄ±ÄŸÄ±na
        # uygun ÅŸekilde temizlenmiÅŸ bir ÅŸablon kullanÄ±yoruz[cite: 308].
        # Format: [relationship, emotional state, setting] [cite: 307, 308]
        structured_caption = (
            f"relationship: {rel_name.lower()}, "
            f"emotional state: happy, "
            f"setting: outdoor"
        )

        # 4. Ã‡Ä±ktÄ± Paketleme
        return {
            'image': image,  # GÃ¶rsel Ã¶zellik vektÃ¶rÃ¼ F_I iÃ§in [cite: 98]
            'caption': structured_caption,  # YapÄ±landÄ±rÄ±lmÄ±ÅŸ metin Ã¶zelliÄŸi F_T iÃ§in [cite: 97, 214]
            'label': torch.tensor(clean_label, dtype=torch.long)  # Tahmin P iÃ§in [cite: 96]
        }

    """
    def __getitem__(self, idx):
        pair_data = self.pairs[idx]
        img_path = os.path.join(self.image_dir, pair_data['filename'])

        # GÃ¶rÃ¼ntÃ¼ yÃ¼kleme ve hata kontrolÃ¼
        try:
            if os.path.exists(img_path):
                image = Image.open(img_path).convert('RGB')
            else:
                image = Image.new('RGB', (224, 224), color='gray')
        except Exception:
            image = Image.new('RGB', (224, 224), color='gray')

        # GÃ¶rÃ¼ntÃ¼ dÃ¶nÃ¼ÅŸÃ¼mleri (ResNet-50 giriÅŸi iÃ§in)
        if self.transform:
            image = self.transform(image)

        # Etiket dÃ¼zeltme (1-6 -> 0-5)
        raw_label = int(pair_data['label'])
        clean_label = max(0, min(raw_label - 1, 5))
        rel_name = self.label_names[clean_label]

        # --- MAKALE UYUMLU: STRUCTURED TEXT EXTRACTION ---
        # Makalede LLM; Aksiyon, Duygu ve Sahne bilgilerini yapÄ±landÄ±rÄ±lmÄ±ÅŸ olarak Ã§Ä±karÄ±r[cite: 109, 133].
        # Bu hiyerarÅŸi "Subject-State-Environment" (Ã–zne-Durum-Ortam) dÃ¼zenini korur[cite: 307].
        # Algoritma 1'e gÃ¶re Ã§Ä±ktÄ± bir dizi (sequence) formunda olmalÄ±dÄ±r[cite: 135].

        # Makaledeki Ã¶rneklere uygun yapÄ±landÄ±rÄ±lmÄ±ÅŸ dizi formatÄ±[cite: 135, 308]:
        # Format: [relationship: X, emotional state: Y, setting: Z]
        structured_caption = f"relationship: {rel_name.lower()}, emotional state: happy, setting: outdoor"
        # --------------------------------------------------

        return {
            'image': image,
            'caption': structured_caption,  # BERT artÄ±k yapÄ±landÄ±rÄ±lmÄ±ÅŸ veriyi iÅŸleyecek [cite: 214]
            'label': torch.tensor(clean_label, dtype=torch.long)
        }


    
    def __getitem__(self, idx):
        pair_data = self.pairs[idx]
        img_path = os.path.join(self.image_dir, pair_data['filename'])

        try:
            if os.path.exists(img_path):
                image = Image.open(img_path).convert('RGB')
            else:
                image = Image.new('RGB', (224, 224), color='gray')
        except Exception:
            # Okuma hatasÄ± olursa (dosya bozuksa vb.) gri resim oluÅŸtur
            image = Image.new('RGB', (224, 224), color='gray')

        # ArtÄ±k image deÄŸiÅŸkeni garanti olarak mevcut
        if self.transform:
            image = self.transform(image)

        # Etiket dÃ¼zeltme (1-6 -> 0-5)
        raw_label = int(pair_data['label'])
        clean_label = max(0, min(raw_label - 1, 5))

        # PISC label_names'e gÃ¶re caption oluÅŸturma
        caption = f"Two people in a {self.label_names[clean_label]} relationship."

        return {
            'image': image,
            'caption': caption,
            'label': torch.tensor(clean_label, dtype=torch.long)
        }
    """


def get_pisc_dataloaders(data_root, batch_size=4, num_workers=0):
    """
    PISC Veri YÃ¼kleyicilerini HazÄ±rlar.
    Makaledeki %80-10-10 daÄŸÄ±lÄ±mÄ±na uygun olarak Test setini de ekler.
    """

    # EÄÄ°TÄ°M Ä°Ã‡Ä°N DAHA SERT VERÄ° ARTIRIMI (Ezberlemeyi Ã¶nlemek iÃ§in)
    train_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.RandomCrop((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.3, contrast=0.3),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # VALIDATION VE TEST Ä°Ã‡Ä°N STANDART DÃ–NÃœÅÃœM
    val_test_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # 1. Datasetleri OluÅŸtur (Train, Val ve Test)
    # PISC dataset yapÄ±sÄ±nda 'test' spliti de mevcuttur[cite: 296, 464].
    train_ds = PISCDataset(data_root, split='train', transform=train_transform)
    val_ds = PISCDataset(data_root, split='val', transform=val_test_transform)
    test_ds = PISCDataset(data_root, split='test', transform=val_test_transform)  # Yeni eklendi

    # SÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ±nÄ± sadece eÄŸitim seti Ã¼zerinden hesapla
    weights = calculate_class_weights(train_ds)

    # 2. Ä°statistikleri YazdÄ±r (Raporundaki 96.568 hedefiyle karÅŸÄ±laÅŸtÄ±rmak iÃ§in)
    print("\n" + "=" * 30)
    print("ğŸ“Š PISC DATASET SPLIT SUMMARY")
    print(f"   Train Pairs: {len(train_ds)}")
    print(f"   Val Pairs:   {len(val_ds)}")
    print(f"   Test Pairs:  {len(test_ds)}")
    print(f"   Total:       {len(train_ds) + len(val_ds) + len(test_ds)}")
    print("=" * 30 + "\n")

    # 3. Dataloader'larÄ± oluÅŸtur
    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)
    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)

    # DÄ°KKAT: ArtÄ±k 4 deÄŸer dÃ¶ndÃ¼rÃ¼yoruz (Train, Val, Test, Weights)
    return train_loader, val_loader, test_loader, weights