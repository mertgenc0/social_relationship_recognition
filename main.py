import os
import torch
# Kendi yazdÄ±ÄŸÄ±n modÃ¼lleri iÃ§e aktar
from data.pisc_dataset_loader import get_pisc_dataloaders
from models.baseline.baseline_model import BaselineModel
from training.losses import CombinedLoss
from training.optimizer import build_optimizer, build_scheduler
from training.trainer import Trainer

def main():
    # --- 1. KonfigÃ¼rasyon ---
    config = {
        'data_root': 'data/dataset',  # Veri setinin yolu
        'num_classes': 6,             # Fine-grained (6 sÄ±nÄ±f)
        'hidden_dim': 256,
        'batch_size': 4,              # M2 Mac belleÄŸi iÃ§in ideal (BERT+ResNet aÄŸÄ±r bir ikili)
        'lr': 1e-4,                   # Ã–ÄŸrenme hÄ±zÄ±
        'num_epochs': 20,             # Toplam eÄŸitim sÃ¼resi
        'save_every': 5,
        'device': 'mps' if torch.backends.mps.is_available() else 'cpu', # M2 GPU (Metal) desteÄŸi
        'checkpoint_dir': 'checkpoints/baseline',
        'log_dir': 'logs/baseline'
    }

    # KlasÃ¶rleri oluÅŸtur
    os.makedirs(config['checkpoint_dir'], exist_ok=True)
    os.makedirs(config['log_dir'], exist_ok=True)

    print(f"ğŸš€ Baseline EÄŸitimi BaÅŸlÄ±yor | Cihaz: {config['device'].upper()}")
    print(f"ğŸ“Š Toplam SÄ±nÄ±f: {config['num_classes']} | Batch Size: {config['batch_size']}")

    # --- 2. DataLoaders (Ã‡alÄ±ÅŸtÄ±ÄŸÄ±nÄ± teyit ettiÄŸimiz loader) ---
    train_loader, val_loader = get_pisc_dataloaders(
        data_root=config['data_root'],
        batch_size=config['batch_size'],
        num_workers=0 # M2 Mac'te stabilite iÃ§in 0 kalmalÄ±
    )

    # --- 3. Model HazÄ±rlÄ±ÄŸÄ± ---
    model = BaselineModel(
        num_classes=config['num_classes'],
        hidden_dim=config['hidden_dim'],
        pretrained_resnet=True
    ).to(config['device'])

    # --- 4. Loss, Optimizer ve Scheduler ---
    # L_total = L_CE + alpha * L_contrastive (Rapordaki formÃ¼l)
    criterion = CombinedLoss(num_classes=config['num_classes'], alpha=0.1)
    optimizer = build_optimizer(model, config)
    scheduler = build_scheduler(optimizer, config, num_epochs=config['num_epochs'])

    # --- 5. Trainer (EÄŸitim DÃ¶ngÃ¼sÃ¼) ---
    trainer = Trainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        criterion=criterion,
        optimizer=optimizer,
        scheduler=scheduler,
        config=config,
        device=config['device'],
        checkpoint_dir=config['checkpoint_dir'],
        log_dir=config['log_dir']
    )

    # --- 6
    print("\nğŸ¬ EÄŸitim dÃ¶ngÃ¼sÃ¼ baÅŸlÄ±yor...")
    trainer.train(num_epochs=config['num_epochs'])


if __name__ == "__main__":
    main()