"""
Multimodal Fusion Module for Baseline Model
Uses MLP to learn adaptive weights for fusing image and text features
"""

import torch
import torch.nn as nn


class AdaptiveFusion(nn.Module):
    """
    Learns to adaptively fuse image and text features

    Pipeline:
    1. Concatenate aligned image and text features
    2. MLP learns fusion weight w âˆˆ [0, 1]
    3. Fused feature = w * image + (1-w) * text

    From baseline paper Equation (3):
    F_fusion = w âŠ™ F_I + (1 - w) âŠ™ F_T
    where w = MLP([F_I; F_T])

    - GÃ¶rÃ¼ntÃ¼nÃ¼n mÃ¼ yoksa metnin mi o anki Ã¶rnek iÃ§in daha Ã¶nemli olduÄŸuna karar veren bir yapÄ±dÄ±r.
    """

    def __init__(self, feature_dim=256, hidden_dim=128):
        super(AdaptiveFusion, self).__init__()

        print(f"ðŸ”§ Initializing Adaptive Fusion Module...")

        ### bir aÄŸÄ±rlÄ±k belirleme aÄŸÄ±dÄ±r. GÃ¶rÃ¼ntÃ¼ ve metni birleÅŸtirip giriÅŸ olarak alÄ±r ve her bir Ã¶zellik kanalÄ± iÃ§in 0 ile 1 arasÄ±nda bir deÄŸer (Sigmoid) Ã¼retir.

        # MLP to learn fusion weights
        self.weight_mlp = nn.Sequential(
            nn.Linear(feature_dim * 2, hidden_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, feature_dim),
            nn.Sigmoid()  # Output weights in [0, 1]
        )

        # Optional: Additional transformation after fusion
        self.fusion_transform = nn.Sequential(
            nn.Linear(feature_dim, feature_dim),
            nn.LayerNorm(feature_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1)
        )

        print(f"âœ… Adaptive Fusion initialized")
        print(f"   Feature dimension: {feature_dim}")
        print(f"   Hidden dimension: {hidden_dim}")

    def forward(self, image_features, text_features):
        """
        Adaptively fuse image and text features

        Args:
            image_features: [batch_size, feature_dim] - aligned image features
            text_features: [batch_size, feature_dim] - aligned text features

        Returns:
            fused_features: [batch_size, feature_dim]
            weights: [batch_size, feature_dim] - fusion weights (for analysis)
        """
        ### Ä°ki vektÃ¶rÃ¼ uÃ§ uca ekler. Boyut 256Ã—2=512 olur.
        # Concatenate features
        concat_features = torch.cat([image_features, text_features], dim=-1)

        ### Model bu 512 boyuta bakÄ±p "Åžu an gÃ¶rÃ¼ntÃ¼ mÃ¼ daha baskÄ±n olmalÄ±, metin mi?" sorusuna cevap veren w aÄŸÄ±rlÄ±klarÄ±nÄ± oluÅŸturur.
        # Learn fusion weights via MLP
        weights = self.weight_mlp(concat_features)  # [batch, feature_dim]

        ### AsÄ±l sihir burasÄ±dÄ±r. EÄŸer weight 0.8 ise, sonucun %80'i gÃ¶rÃ¼ntÃ¼den, %20'si metinden gelir
        # Adaptive weighted fusion
        fused = weights * image_features + (1 - weights) * text_features
        # [batch, feature_dim]

        ### BirleÅŸtirme bittikten sonra sonucu temizlemek ve daha yÃ¼ksek seviyeli bir temsil oluÅŸturmak iÃ§in son bir Lineer katman ve Normalizasyon uygular.
        # Optional transformation
        fused_features = self.fusion_transform(fused)

        return fused_features, weights


class SimpleFusion(nn.Module):
    """
    Simple baseline fusion: concatenate and project
    Used for ablation studies

    - karÅŸÄ±laÅŸtÄ±rma (ablation study) yapmak iÃ§in yazÄ±lmÄ±ÅŸ basit bir yapÄ±dÄ±r.

    - Ne yapar? GÃ¶rÃ¼ntÃ¼ ve metni uÃ§ uca ekler (concatenate) ve bir Lineer katmanla doÄŸrudan orijinal boyuta geri indirir.

    - FarkÄ± nedir? "Hangisi daha Ã¶nemli?" diye dÃ¼ÅŸÃ¼nmez; her iki veriyi de sabit bir matris Ã§arpÄ±mÄ±yla karÄ±ÅŸtÄ±rÄ±r.
     Daha hÄ±zlÄ±dÄ±r ama daha az zekidir.
    """

    def __init__(self, feature_dim=256):
        super(SimpleFusion, self).__init__()

        self.fusion = nn.Sequential(
            nn.Linear(feature_dim * 2, feature_dim),
            nn.LayerNorm(feature_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1)
        )

    def forward(self, image_features, text_features):
        """Simple concatenation and projection"""
        concat = torch.cat([image_features, text_features], dim=-1)
        fused = self.fusion(concat)
        return fused, None  # No weights for simple fusion

"""
if __name__ == "__main__":
    import torch
    import clip
    from PIL import Image

    print(" ------KENDÄ° VERÄ°LERÄ°MLE TEST BAÅžLIYOR-----")
    

    # 1. Cihaz ve Model HazÄ±rlÄ±ÄŸÄ±
    device = "cuda" if torch.cuda.is_available() else "cpu"
    # CLIP: Resim ve metni vektÃ¶re Ã§eviren yardÄ±mcÄ± model
    clip_model, preprocess = clip.load("ViT-B/32", device=device)

    # Senin Adaptive Fusion modelin (CLIP ViT-B/32 Ã§Ä±ktÄ± boyutu 512'dir)
    feature_dim = 512
    adaptive_fusion = AdaptiveFusion(feature_dim=feature_dim, hidden_dim=256).to(device)
    adaptive_fusion.eval()

    # 2. KENDÄ° VERÄ°LERÄ°NÄ° BURAYA EKLE
    # ---------------------------------------------------------
    resim_yolu = "data/dataset/image/00033.jpg"  # Kendi resminin adÄ±
    metin_icerigi = "Two Cowekres are singing in the restourant"  # Kendi metnin
    # ---------------------------------------------------------

    try:
        # Resmi iÅŸle ve vektÃ¶re Ã§evir
        image = preprocess(Image.open(resim_yolu)).unsqueeze(0).to(device)
        # Metni iÅŸle ve vektÃ¶re Ã§evir
        text = clip.tokenize([metin_icerigi]).to(device)

        with torch.no_grad():
            image_features = clip_model.encode_image(image).float()
            text_features = clip_model.encode_text(text).float()

            # --- ASIL FUSION Ä°ÅžLEMÄ° ---
            fused_adaptive, weights = adaptive_fusion(image_features, text_features)
            # --------------------------

        print(f"\n-  GiriÅŸler BaÅŸarÄ±yla HazÄ±rlandÄ±:")
        print(f"   - Resim: {resim_yolu}")
        print(f"   - Metin: {metin_icerigi}")

        # Orijinal Analiz KÄ±smÄ± (HiÃ§bir ÅŸeyi silmeden)
        print(f"\n-  Analiz SonuÃ§larÄ±:")
        print(f"   Fused features shape: {fused_adaptive.shape}")
        print(f"   Fusion weights shape: {weights.shape}")

        img_w_mean = weights.mean().item()
        txt_w_mean = 1.0 - img_w_mean

        print(f"   Weight statistics:")
        print(f"     Mean (Image Weight): {img_w_mean:.3f}")
        print(f"     Min: {weights.min():.3f}, Max: {weights.max():.3f}")

        print("\n-  PRATÄ°K YORUM:")
        print(f"   Model bu Ã¶rnekte bilginin %{img_w_mean * 100:.1f} kadarÄ±nÄ± GÃ–RSELden,")
        print(f"   %{txt_w_mean * 100:.1f} kadarÄ±nÄ± METÄ°Nden almayÄ± tercih etti.")

        # Model Ä°statistikleri (Orijinal kodundaki gibi)
        adaptive_params = sum(p.numel() for p in adaptive_fusion.parameters())
        print(f"\n-  Model Statistics:")
        print(f"   Adaptive Fusion Total parameters: {adaptive_params:,}")

    except FileNotFoundError:
        print(f"\n-  HATA: '{resim_yolu}' dosyasÄ± bulunamadÄ±! LÃ¼tfen resim yolunu kontrol et.")
    except Exception as e:
        print(f"\n-  Bir hata oluÅŸtu: {e}")

   
    print("---- Test TamamlandÄ±!---- ")
    

"""
# Test code
if __name__ == "__main__":
    print("=" * 60)
    print("ðŸ§ª Testing Fusion Module")
    print("=" * 60)

    # Create fusion modules
    print("\nðŸ“Š Testing Adaptive Fusion...")
    adaptive_fusion = AdaptiveFusion(feature_dim=256, hidden_dim=128)
    adaptive_fusion.eval()

    print("\nðŸ“Š Testing Simple Fusion...")
    simple_fusion = SimpleFusion(feature_dim=256)
    simple_fusion.eval()

    # Test with sample features
    print(f"\nðŸ“Š Creating test features...")
    batch_size = 4
    feature_dim = 256

    image_features = torch.randn(batch_size, feature_dim)
    text_features = torch.randn(batch_size, feature_dim)

    print(f"   Image features shape: {image_features.shape}")
    print(f"   Text features shape: {text_features.shape}")

    # Test Adaptive Fusion
    print(f"\nâš™ï¸  Running adaptive fusion...")
    with torch.no_grad():
        fused_adaptive, weights = adaptive_fusion(image_features, text_features)

    print(f"\nâœ… Adaptive fusion successful!")
    print(f"   Fused features shape: {fused_adaptive.shape}")  # [4, 256]
    print(f"   Fusion weights shape: {weights.shape}")  # [4, 256]
    print(f"   Weight statistics:")
    print(f"     Mean: {weights.mean():.3f}")
    print(f"     Std: {weights.std():.3f}")
    print(f"     Min: {weights.min():.3f}, Max: {weights.max():.3f}")
    print(f"   Interpretation: {weights.mean():.1%} image, {(1 - weights.mean()):.1%} text")

    # Test Simple Fusion
    print(f"\nâš™ï¸  Running simple fusion...")
    with torch.no_grad():
        fused_simple, _ = simple_fusion(image_features, text_features)

    print(f"\nâœ… Simple fusion successful!")
    print(f"   Fused features shape: {fused_simple.shape}")  # [4, 256]

    # Compare outputs
    print(f"\nðŸ” Comparing fusion methods...")
    print(f"   Adaptive fusion output range: [{fused_adaptive.min():.3f}, {fused_adaptive.max():.3f}]")
    print(f"   Simple fusion output range: [{fused_simple.min():.3f}, {fused_simple.max():.3f}]")

    # Test edge cases
    print(f"\nðŸ§ª Testing edge cases...")

    # Case 1: Identical features (should give equal weights ~0.5)
    identical = torch.randn(2, feature_dim)
    with torch.no_grad():
        _, identical_weights = adaptive_fusion(identical, identical)
    print(f"   Identical features â†’ weights: {identical_weights.mean():.3f} (should be ~0.5)")

    # Case 2: Very different features
    strong_image = torch.randn(2, feature_dim) * 10  # Strong signal
    weak_text = torch.randn(2, feature_dim) * 0.1  # Weak signal
    with torch.no_grad():
        _, diff_weights = adaptive_fusion(strong_image, weak_text)
    print(f"   Strong image + weak text â†’ weights: {diff_weights.mean():.3f}")
    print(f"   (Higher weight = more reliance on image)")

    # Test single sample
    print(f"\nðŸ” Testing single sample...")
    single_image = torch.randn(1, feature_dim)
    single_text = torch.randn(1, feature_dim)
    with torch.no_grad():
        single_fused, single_weights = adaptive_fusion(single_image, single_text)

    print(f"   Single fused shape: {single_fused.shape}")  # [1, 256]
    print(f"   Single weights mean: {single_weights.mean():.3f}")

    # Memory usage
    adaptive_params = sum(p.numel() for p in adaptive_fusion.parameters())
    adaptive_trainable = sum(p.numel() for p in adaptive_fusion.parameters() if p.requires_grad)

    simple_params = sum(p.numel() for p in simple_fusion.parameters())
    simple_trainable = sum(p.numel() for p in simple_fusion.parameters() if p.requires_grad)

    print(f"\nðŸ“Š Model Statistics:")
    print(f"   Adaptive Fusion:")
    print(f"     Total parameters: {adaptive_params:,}")
    print(f"     Trainable parameters: {adaptive_trainable:,}")
    print(f"   Simple Fusion:")
    print(f"     Total parameters: {simple_params:,}")
    print(f"     Trainable parameters: {simple_trainable:,}")

    print("\n" + "=" * 60)
    print("âœ… Fusion Module Test PASSED!")
    print("=" * 60)

    print("\nðŸ’¡ Practical Interpretation:")
    print("   - Adaptive fusion learns to weight modalities dynamically")
    print("   - Weight ~0.5 â†’ both modalities equally important")
    print("   - Weight >0.5 â†’ rely more on image")
    print("   - Weight <0.5 â†’ rely more on text")
    print("   - Simple fusion is faster but less flexible")
